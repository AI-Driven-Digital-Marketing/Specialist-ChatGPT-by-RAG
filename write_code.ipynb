{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ab419e4c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting environment.yml\n"
     ]
    }
   ],
   "source": [
    "%%writefile environment.yml\n",
    "name: TorchEnv\n",
    "dependencies:\n",
    "  - numpy\n",
    "  - pandas\n",
    "  - openai\n",
    "  - pip:\n",
    "    - matplotlib\n",
    "    - pinecone-client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69ee42c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile Welcome.py\n",
    "import streamlit as st\n",
    "st.write('Welcome :)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bc642365",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing pages/RAG-ChatGPT.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile pages/RAG-ChatGPT.py\n",
    "import openai\n",
    "import pinecone\n",
    "import streamlit as st\n",
    "@st.cache_resource\n",
    "def initialize():\n",
    "    openai.api_key = st.secrets['openai_key']\n",
    "    index_name = 'openai-youtube-transcriptions'\n",
    "\n",
    "    # initialize connection to pinecone (get API key at app.pinecone.io)\n",
    "    pinecone.init(\n",
    "        api_key=st.secrets['pinecone_key'],\n",
    "        environment=st.secrets['pinecone_env']  # may be different, check at app.pinecone.io\n",
    "    )\n",
    "\n",
    "    # check if index already exists (it shouldn't if this is first time)\n",
    "    if index_name not in pinecone.list_indexes():\n",
    "        # if does not exist, create index\n",
    "        pinecone.create_index(\n",
    "            index_name,\n",
    "            dimension=1536,\n",
    "            metric='cosine',\n",
    "            metadata_config={'indexed': ['title']}\n",
    "        )\n",
    "    # connect to index\n",
    "    index = pinecone.Index(index_name)\n",
    "    return index\n",
    "index = initialize()\n",
    "\n",
    "def complete(prompt):\n",
    "    # query text-davinci-003\n",
    "    res = openai.Completion.create(\n",
    "        engine='text-davinci-003',\n",
    "        prompt=prompt,\n",
    "        temperature=0,\n",
    "        max_tokens=400,\n",
    "        top_p=1,\n",
    "        frequency_penalty=0,\n",
    "        presence_penalty=0,\n",
    "        stop=None\n",
    "    )\n",
    "    return res['choices'][0]['text'].strip()\n",
    "\n",
    "\n",
    "limit = 3750\n",
    "embed_model = \"text-embedding-ada-002\"\n",
    "def retrieve(query):\n",
    "    res = openai.Embedding.create(\n",
    "        input=[query],\n",
    "        engine=embed_model\n",
    "    )\n",
    "\n",
    "    # retrieve from Pinecone\n",
    "    xq = res['data'][0]['embedding']\n",
    "\n",
    "    # get relevant contexts\n",
    "    res = index.query(xq, top_k=3, include_metadata=True)\n",
    "    contexts = [\n",
    "        x['metadata']['text'] for x in res['matches']\n",
    "    ]\n",
    "\n",
    "    # build our prompt with the retrieved contexts included\n",
    "    prompt_start = (\n",
    "        \"Answer the question based on the context below.\\n\\n\"+\n",
    "        \"Context:\\n\"\n",
    "    )\n",
    "    prompt_end = (\n",
    "        f\"\\n\\nQuestion: {query}\\nAnswer:\"\n",
    "    )\n",
    "    # append contexts until hitting limit\n",
    "    for i in range(1, len(contexts)):\n",
    "        if len(\"\\n\\n---\\n\\n\".join(contexts[:i])) >= limit:\n",
    "            prompt = (\n",
    "                prompt_start +\n",
    "                \"\\n\\n---\\n\\n\".join(contexts[:i-1]) +\n",
    "                prompt_end\n",
    "            )\n",
    "            break\n",
    "        elif i == len(contexts)-1:\n",
    "            prompt = (\n",
    "                prompt_start +\n",
    "                \"\\n\\n---\\n\\n\".join(contexts) +\n",
    "                prompt_end\n",
    "            )\n",
    "    return prompt\n",
    "\n",
    "_,col1,_ = st.columns([1,8,1])\n",
    "with col1: \n",
    "    form = st.form(key='myform')\n",
    "    query = form.text_input( \"Enter some text ðŸ‘‡\",\n",
    "        placeholder=\"Write your prompt here...\",\n",
    "    )\n",
    "    submit = form.form_submit_button('Submit')\n",
    "if submit:\n",
    "    # get context, additional info from pinecone\n",
    "    query_with_contexts = retrieve(query)\n",
    "    # call openai API\n",
    "    output = complete(query_with_contexts)\n",
    "\n",
    "    st.write(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a152869d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torchgpu",
   "language": "python",
   "name": "torchgpu"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
